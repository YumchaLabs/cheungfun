//! Comprehensive tests for KeywordExtractor.
//!
//! These tests cover both unit tests with mocks and integration tests with real LLM calls.

use async_trait::async_trait;
use cheungfun_core::{
    traits::{TypedTransform, TypedData, NodeState},
    types::{ChunkInfo, Node},
};
use cheungfun_indexing::transformers::{KeywordExtractor, KeywordExtractorConfig};
use siumai::{prelude::*, LlmClient, LlmError};
use std::{collections::HashMap, sync::Arc};
use uuid::Uuid;

/// Mock LLM client for testing without API calls.
#[derive(Debug, Clone)]
pub struct MockLlmClient {
    pub responses: HashMap<String, String>,
    pub default_response: String,
}

impl MockLlmClient {
    pub fn new() -> Self {
        let mut responses = HashMap::new();

        // Add some predefined responses for testing
        responses.insert(
            "ai_keywords".to_string(),
            "KEYWORDS: artificial intelligence, machine learning, deep learning, neural networks, data science".to_string(),
        );
        responses.insert(
            "climate_keywords".to_string(),
            "KEYWORDS: climate change, global warming, greenhouse gases, environmental impact, sustainability".to_string(),
        );

        Self {
            responses,
            default_response: "KEYWORDS: technology, innovation, research, development, science"
                .to_string(),
        }
    }

    pub fn with_response(mut self, key: String, response: String) -> Self {
        self.responses.insert(key, response);
        self
    }
}

#[async_trait]
impl ChatCapability for MockLlmClient {
    async fn chat(&self, messages: Vec<ChatMessage>) -> Result<ChatResponse, LlmError> {
        // Extract the prompt content
        let prompt = messages
            .first()
            .and_then(|msg| msg.content.as_text())
            .unwrap_or("");

        // Determine response based on prompt content
        let response_text = if prompt.to_lowercase().contains("artificial intelligence") {
            self.responses
                .get("ai_keywords")
                .unwrap_or(&self.default_response)
                .clone()
        } else if prompt.to_lowercase().contains("climate") {
            self.responses
                .get("climate_keywords")
                .unwrap_or(&self.default_response)
                .clone()
        } else {
            self.default_response.clone()
        };

        Ok(ChatResponse::new(ChatContent::text(response_text)))
    }

    async fn chat_stream(
        &self,
        _messages: Vec<ChatMessage>,
        _options: Option<ChatStreamOptions>,
    ) -> Result<
        Box<dyn futures::Stream<Item = Result<ChatStreamEvent, LlmError>> + Send + Unpin>,
        LlmError,
    > {
        unimplemented!("Streaming not needed for tests")
    }
}

impl LlmClient for MockLlmClient {
    fn provider_name(&self) -> &'static str {
        "mock"
    }

    fn supported_models(&self) -> Vec<String> {
        vec!["mock-model".to_string()]
    }

    fn capabilities(&self) -> ProviderCapabilities {
        ProviderCapabilities::new().with_chat()
    }

    fn as_any(&self) -> &dyn std::any::Any {
        self
    }

    fn clone_box(&self) -> Box<dyn LlmClient> {
        Box::new(self.clone())
    }
}

/// Create sample nodes for testing.
fn create_test_nodes(contents: Vec<&str>) -> Vec<Node> {
    contents
        .into_iter()
        .enumerate()
        .map(|(i, content)| {
            Node::new(
                content.to_string(),
                Uuid::new_v4(),
                ChunkInfo {
                    start_offset: i * 100,
                    end_offset: (i + 1) * 100,
                    chunk_index: i,
                },
            )
        })
        .collect()
}

#[tokio::test]
async fn test_keyword_extractor_basic() {
    let mock_client = MockLlmClient::new();
    let config = KeywordExtractorConfig::new().with_show_progress(false);
    let extractor = KeywordExtractor::new(Arc::new(mock_client), config).unwrap();

    let nodes = create_test_nodes(vec![
        "Artificial intelligence is transforming industries with machine learning algorithms.",
    ]);

    let result = extractor.transform(TransformInput::Nodes(nodes)).await;
    assert!(result.is_ok());

    let enhanced_nodes = result.unwrap();
    assert_eq!(enhanced_nodes.len(), 1);

    // Check that the node has the excerpt_keywords metadata
    let node = &enhanced_nodes[0];
    assert!(node.metadata.contains_key("excerpt_keywords"));
    let keywords = node.metadata.get("excerpt_keywords").unwrap();
    let keywords_str = keywords.as_str().unwrap();
    assert!(!keywords_str.is_empty());
    assert!(keywords_str.contains("artificial intelligence"));
}

#[tokio::test]
async fn test_keyword_extractor_multiple_nodes() {
    let mock_client = MockLlmClient::new();
    let config = KeywordExtractorConfig::new().with_show_progress(false);
    let extractor = KeywordExtractor::new(Arc::new(mock_client), config).unwrap();

    let nodes = create_test_nodes(vec![
        "Artificial intelligence and machine learning are revolutionizing technology.",
        "Climate change is affecting global weather patterns and ecosystems.",
    ]);

    let result = extractor.transform(TransformInput::Nodes(nodes)).await;
    assert!(result.is_ok());

    let enhanced_nodes = result.unwrap();
    assert_eq!(enhanced_nodes.len(), 2);

    // Check that all nodes have keywords
    for node in enhanced_nodes {
        assert!(node.metadata.contains_key("excerpt_keywords"));
        let keywords = node.metadata.get("excerpt_keywords").unwrap();
        assert!(!keywords.as_str().unwrap().is_empty());
    }
}

#[tokio::test]
async fn test_keyword_extractor_config_validation() {
    let mock_client = MockLlmClient::new();

    // Test invalid configuration (0 keywords)
    let invalid_config = KeywordExtractorConfig::new().with_keywords(0);
    let result =
        TryInto::<KeywordExtractor>::try_into((Arc::new(mock_client.clone()), invalid_config));
    // This would fail in KeywordExtractor::new()

    // Test valid configuration
    let valid_config = KeywordExtractorConfig::new().with_keywords(3);
    let result = KeywordExtractor::new(Arc::new(mock_client), valid_config);
    assert!(result.is_ok());
}

#[tokio::test]
async fn test_keyword_extractor_empty_nodes() {
    let mock_client = MockLlmClient::new();
    let config = KeywordExtractorConfig::new().with_show_progress(false);
    let extractor = KeywordExtractor::new(Arc::new(mock_client), config).unwrap();

    let result = extractor.transform(TypedData::from_nodes(vec![])).await;
    assert!(result.is_ok());

    let enhanced_nodes = result.unwrap().into_nodes();
    assert!(enhanced_nodes.is_empty());
}

#[tokio::test]
async fn test_keyword_extractor_single_node() {
    let mock_client = MockLlmClient::new();
    let config = KeywordExtractorConfig::new().with_show_progress(false);
    let extractor = KeywordExtractor::new(Arc::new(mock_client), config).unwrap();

    let node = Node::new(
        "Quantum computing uses quantum mechanics principles.".to_string(),
        Uuid::new_v4(),
        ChunkInfo {
            start_char_idx: Some(0),
            end_char_idx: Some(42),
            chunk_index: Some(0),
        },
    );

    let result = extractor.transform(TypedData::from_nodes(vec![node])).await;
    assert!(result.is_ok());

    let enhanced_nodes = result.unwrap().into_nodes();
    assert_eq!(enhanced_nodes.len(), 1);
    assert!(enhanced_nodes[0].metadata.contains_key("excerpt_keywords"));
}

#[tokio::test]
async fn test_keyword_extractor_invalid_input() {
    let mock_client = MockLlmClient::new();
    let config = KeywordExtractorConfig::new();
    let extractor = KeywordExtractor::new(Arc::new(mock_client), config).unwrap();

    // Test with document input (should fail)
    let document = cheungfun_core::Document::new("Test content");
    let result = extractor
        .transform(TypedData::from_documents(vec![document]))
        .await;
    assert!(result.is_err());
}

#[tokio::test]
async fn test_keyword_extractor_builder() {
    let mock_client = MockLlmClient::new();

    let extractor = KeywordExtractor::builder(Arc::new(mock_client))
        .keywords(8)
        .show_progress(false)
        .max_context_length(1000)
        .lowercase_keywords(false)
        .remove_duplicates(true)
        .build();

    assert!(extractor.is_ok());
    let extractor = extractor.unwrap();

    // Test the configuration was applied
    let config_map = extractor.config();
    assert_eq!(config_map.get("keywords").unwrap().as_u64().unwrap(), 8);
    assert_eq!(
        config_map.get("show_progress").unwrap().as_bool().unwrap(),
        false
    );
    assert_eq!(
        config_map
            .get("max_context_length")
            .unwrap()
            .as_u64()
            .unwrap(),
        1000
    );
    assert_eq!(
        config_map
            .get("lowercase_keywords")
            .unwrap()
            .as_bool()
            .unwrap(),
        false
    );
    assert_eq!(
        config_map
            .get("remove_duplicates")
            .unwrap()
            .as_bool()
            .unwrap(),
        true
    );
}

#[tokio::test]
async fn test_keyword_extractor_can_transform() {
    let mock_client = MockLlmClient::new();
    let config = KeywordExtractorConfig::new();
    let extractor = KeywordExtractor::new(Arc::new(mock_client), config).unwrap();

    // Should accept nodes
    let node = Node::new("test".to_string(), Uuid::new_v4(), ChunkInfo::default());
    assert!(extractor.can_transform(&TransformInput::Node(node)).await);
    assert!(
        extractor
            .can_transform(&TransformInput::Nodes(vec![]))
            .await
    );

    // Should reject documents
    let document = cheungfun_core::Document::new("test", None);
    assert!(
        !extractor
            .can_transform(&TransformInput::Document(document))
            .await
    );
    assert!(
        !extractor
            .can_transform(&TransformInput::Documents(vec![]))
            .await
    );
}

#[test]
fn test_keyword_extractor_name() {
    let mock_client = MockLlmClient::new();
    let config = KeywordExtractorConfig::new();
    let extractor = KeywordExtractor::new(Arc::new(mock_client), config).unwrap();

    assert_eq!(extractor.name(), "KeywordExtractor");
}

#[test]
fn test_keyword_extractor_config_builder() {
    let config = KeywordExtractorConfig::new()
        .with_keywords(10)
        .with_show_progress(false)
        .with_num_workers(8)
        .with_max_context_length(5000)
        .with_lowercase_keywords(false)
        .with_remove_duplicates(false);

    assert_eq!(config.keywords, 10);
    assert!(!config.show_progress);
    assert_eq!(config.num_workers, 8);
    assert_eq!(config.max_context_length, 5000);
    assert!(!config.lowercase_keywords);
    assert!(!config.remove_duplicates);
}

#[test]
fn test_prompt_template_validation() {
    // Test that template must contain required placeholders
    let template_without_context = "Give {keywords} keywords.";
    let template_without_keywords = "Extract keywords from {context_str}.";
    let valid_template = "Extract {keywords} keywords from {context_str}.";

    // These would fail in KeywordExtractor::new() validation
    assert!(!template_without_context.contains("{context_str}"));
    assert!(!template_without_keywords.contains("{keywords}"));
    assert!(valid_template.contains("{context_str}") && valid_template.contains("{keywords}"));
}

#[test]
fn test_keyword_parsing() {
    // Test keyword parsing logic
    let test_cases = vec![
        (
            "KEYWORDS: AI, Machine Learning, Deep Learning",
            vec!["ai", "machine learning", "deep learning"],
        ),
        (
            "ai, machine learning, deep learning, neural networks",
            vec!["ai", "machine learning", "deep learning", "neural networks"],
        ),
        (
            "Keywords: Technology, Innovation, Future",
            vec!["technology", "innovation", "future"],
        ),
        ("", vec![]),
    ];

    for (input, expected) in test_cases {
        let result = parse_keywords_test_helper(input, true, true, 5);
        assert_eq!(result, expected, "Failed for input: '{}'", input);
    }
}

// Helper function to test keyword parsing logic
fn parse_keywords_test_helper(
    response: &str,
    lowercase: bool,
    remove_duplicates: bool,
    max_keywords: usize,
) -> Vec<String> {
    let cleaned_response = response.trim().trim_matches('"').trim_matches('\'').trim();

    let keywords_text = if let Some(pos) = cleaned_response.to_lowercase().find("keywords:") {
        &cleaned_response[pos + 9..]
    } else {
        cleaned_response
    };

    let mut keywords: Vec<String> = keywords_text
        .split(',')
        .map(|kw| kw.trim().to_string())
        .filter(|kw| !kw.is_empty())
        .collect();

    if lowercase {
        keywords = keywords.into_iter().map(|kw| kw.to_lowercase()).collect();
    }

    if remove_duplicates {
        keywords.sort();
        keywords.dedup();
    }

    keywords.truncate(max_keywords);
    keywords
}
