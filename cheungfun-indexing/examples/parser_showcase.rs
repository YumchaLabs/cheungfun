//! Parser Showcase Example
//!
//! This example demonstrates all the different parsers available in cheungfun-indexing
//! and shows how to use them effectively for different types of content.

use cheungfun_core::{Document, traits::{Transform, TransformInput}};
use cheungfun_indexing::node_parser::{
    text::{
        SentenceSplitter, TokenTextSplitter, MarkdownNodeParser, 
        SentenceWindowNodeParser, CodeSplitter
    },
    config::MarkdownConfig,
    NodeParser,
};
use cheungfun_indexing::loaders::ProgrammingLanguage;
use std::time::Instant;
use tracing::{info, Level};
use tracing_subscriber;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_max_level(Level::INFO)
        .init();

    println!("ğŸš€ Cheungfun Indexing Parser Showcase");
    println!("=====================================");

    info!("ğŸš€ Cheungfun Indexing Parser Showcase");
    info!("=====================================");

    // Sample content for different parsers
    let text_content = r#"
        äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ä¸–ç•Œã€‚æœºå™¨å­¦ä¹ ç®—æ³•èƒ½å¤Ÿä»å¤§é‡æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ã€‚
        æ·±åº¦å­¦ä¹ ç½‘ç»œå¯ä»¥è¯†åˆ«å›¾åƒã€ç†è§£è¯­è¨€ã€ç”Ÿæˆå†…å®¹ã€‚è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯è®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£äººç±»è¯­è¨€ã€‚
        
        RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ä¸€ç§æ–°å…´çš„AIæ¶æ„ã€‚å®ƒç»“åˆäº†ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬ç”Ÿæˆçš„ä¼˜åŠ¿ã€‚
        é€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ŒRAGç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆæ›´å‡†ç¡®ã€æ›´æœ‰æ ¹æ®çš„å›ç­”ã€‚
    "#;

    let markdown_content = r#"# Cheungfun RAG Framework

Cheungfun æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„ RAG æ¡†æ¶ï¼Œä½¿ç”¨ Rust ç¼–å†™ã€‚

## æ ¸å¿ƒç‰¹æ€§

### é«˜æ€§èƒ½
- é›¶æ‹·è´å­—ç¬¦ä¸²å¤„ç†
- å¹¶è¡Œå¤„ç†æ”¯æŒ
- å†…å­˜å®‰å…¨ä¿è¯

### æ¨¡å—åŒ–è®¾è®¡
- ç»Ÿä¸€çš„ Transform æ¥å£
- å¯æ’æ‹”çš„ç»„ä»¶æ¶æ„
- ä¸°å¯Œçš„é…ç½®é€‰é¡¹

## æ”¯æŒçš„åŠŸèƒ½

### æ–‡æ¡£åŠ è½½
æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼çš„åŠ è½½å’Œå¤„ç†ã€‚

### æ–‡æœ¬åˆ†å‰²
æä¾›å¤šç§åˆ†å‰²ç­–ç•¥ä»¥é€‚åº”ä¸åŒåœºæ™¯ã€‚
"#;

    let code_content = r#"
use std::collections::HashMap;
use serde::{Deserialize, Serialize};

/// ç”¨æˆ·é…ç½®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserConfig {
    pub name: String,
    pub email: String,
    pub preferences: HashMap<String, String>,
}

impl UserConfig {
    /// åˆ›å»ºæ–°çš„ç”¨æˆ·é…ç½®
    pub fn new(name: String, email: String) -> Self {
        Self {
            name,
            email,
            preferences: HashMap::new(),
        }
    }
    
    /// æ·»åŠ åå¥½è®¾ç½®
    pub fn add_preference(&mut self, key: String, value: String) {
        self.preferences.insert(key, value);
    }
    
    /// è·å–åå¥½è®¾ç½®
    pub fn get_preference(&self, key: &str) -> Option<&String> {
        self.preferences.get(key)
    }
}

/// é…ç½®ç®¡ç†å™¨
pub struct ConfigManager {
    configs: HashMap<String, UserConfig>,
}

impl ConfigManager {
    pub fn new() -> Self {
        Self {
            configs: HashMap::new(),
        }
    }
    
    pub fn add_user(&mut self, id: String, config: UserConfig) {
        self.configs.insert(id, config);
    }
}
"#;

    // 1. Sentence Splitter Demo
    info!("\nğŸ“ 1. Sentence Splitter Demo");
    info!("============================");
    
    let sentence_splitter = SentenceSplitter::from_defaults(150, 30)?;
    let start = Instant::now();
    
    let input = TransformInput::Document(Document::new(text_content));
    let sentence_nodes = sentence_splitter.transform(input).await?;
    let duration = start.elapsed();
    
    info!("ç”ŸæˆèŠ‚ç‚¹æ•°: {}", sentence_nodes.len());
    info!("å¤„ç†æ—¶é—´: {:?}", duration);
    for (i, node) in sentence_nodes.iter().take(2).enumerate() {
        info!("èŠ‚ç‚¹ {}: {}", i + 1, node.content.trim().chars().take(50).collect::<String>() + "...");
    }

    // 2. Token Text Splitter Demo
    info!("\nğŸ”¢ 2. Token Text Splitter Demo");
    info!("==============================");
    
    let token_splitter = TokenTextSplitter::from_defaults(100, 20)?;
    let start = Instant::now();
    
    let input = TransformInput::Document(Document::new(text_content));
    let token_nodes = token_splitter.transform(input).await?;
    let duration = start.elapsed();
    
    info!("ç”ŸæˆèŠ‚ç‚¹æ•°: {}", token_nodes.len());
    info!("å¤„ç†æ—¶é—´: {:?}", duration);
    for (i, node) in token_nodes.iter().take(2).enumerate() {
        info!("èŠ‚ç‚¹ {}: {}", i + 1, node.content.trim().chars().take(50).collect::<String>() + "...");
    }

    // 3. Markdown Parser Demo
    info!("\nğŸ“„ 3. Markdown Parser Demo");
    info!("===========================");
    
    let markdown_parser = MarkdownNodeParser::new()
        .with_max_header_depth(3)
        .with_preserve_header_hierarchy(true);
    let start = Instant::now();
    
    let markdown_nodes = <MarkdownNodeParser as NodeParser>::parse_nodes(&markdown_parser, &[Document::new(markdown_content)], false).await?;
    let duration = start.elapsed();
    
    info!("ç”ŸæˆèŠ‚ç‚¹æ•°: {}", markdown_nodes.len());
    info!("å¤„ç†æ—¶é—´: {:?}", duration);
    for (i, node) in markdown_nodes.iter().take(3).enumerate() {
        let header = node.metadata.get("header")
            .map(|h| h.as_str().unwrap_or(""))
            .unwrap_or("(æ— æ ‡é¢˜)");
        let path = node.metadata.get("header_path")
            .map(|p| p.as_str().unwrap_or(""))
            .unwrap_or("");
        info!("èŠ‚ç‚¹ {}: æ ‡é¢˜='{}', è·¯å¾„='{}'", i + 1, header, path);
    }

    // 4. Sentence Window Parser Demo
    info!("\nğŸªŸ 4. Sentence Window Parser Demo");
    info!("==================================");
    
    let window_parser = SentenceWindowNodeParser::new()
        .with_window_size(1)
        .with_window_metadata_key("context");
    let start = Instant::now();
    
    let window_nodes = <SentenceWindowNodeParser as NodeParser>::parse_nodes(&window_parser, &[Document::new(text_content)], false).await?;
    let duration = start.elapsed();
    
    info!("ç”ŸæˆèŠ‚ç‚¹æ•°: {}", window_nodes.len());
    info!("å¤„ç†æ—¶é—´: {:?}", duration);
    for (i, node) in window_nodes.iter().take(2).enumerate() {
        let context = node.metadata.get("context")
            .map(|c| c.as_str().unwrap_or(""))
            .unwrap_or("");
        info!("èŠ‚ç‚¹ {}: å†…å®¹='{}', ä¸Šä¸‹æ–‡é•¿åº¦={}", 
              i + 1, 
              node.content.trim().chars().take(30).collect::<String>() + "...",
              context.len());
    }

    // 5. Code Splitter Demo
    info!("\nğŸ’» 5. Code Splitter Demo");
    info!("========================");
    
    let code_splitter = CodeSplitter::from_defaults(
        ProgrammingLanguage::Rust,
        20,   // chunk_lines
        5,    // chunk_lines_overlap
        1000  // max_chars
    )?;
    let start = Instant::now();
    
    let code_nodes = <CodeSplitter as NodeParser>::parse_nodes(&code_splitter, &[Document::new(code_content)], false).await?;
    let duration = start.elapsed();
    
    info!("ç”ŸæˆèŠ‚ç‚¹æ•°: {}", code_nodes.len());
    info!("å¤„ç†æ—¶é—´: {:?}", duration);
    for (i, node) in code_nodes.iter().take(3).enumerate() {
        let first_line = node.content.lines().next().unwrap_or("").trim();
        info!("èŠ‚ç‚¹ {}: {}", i + 1, first_line);
    }

    // 6. Performance Comparison
    info!("\nâš¡ 6. Performance Comparison");
    info!("============================");

    let test_doc = Document::new(text_content.repeat(10)); // 10x larger content

    // Test SentenceSplitter performance
    let start = Instant::now();
    let sentence_splitter = SentenceSplitter::from_defaults(200, 40)?;
    let input = TransformInput::Document(test_doc.clone());
    let sentence_nodes = sentence_splitter.transform(input).await?;
    let sentence_duration = start.elapsed();
    info!("SentenceSplitter: {} èŠ‚ç‚¹, {:?}", sentence_nodes.len(), sentence_duration);

    // Test TokenTextSplitter performance
    let start = Instant::now();
    let token_splitter = TokenTextSplitter::from_defaults(150, 30)?;
    let input = TransformInput::Document(test_doc.clone());
    let token_nodes = token_splitter.transform(input).await?;
    let token_duration = start.elapsed();
    info!("TokenTextSplitter: {} èŠ‚ç‚¹, {:?}", token_nodes.len(), token_duration);

    // Test MarkdownNodeParser performance
    let start = Instant::now();
    let md_parser = MarkdownNodeParser::new();
    let md_nodes = <MarkdownNodeParser as NodeParser>::parse_nodes(&md_parser, &[test_doc], false).await?;
    let md_duration = start.elapsed();
    info!("MarkdownNodeParser: {} èŠ‚ç‚¹, {:?}", md_nodes.len(), md_duration);

    // 7. Configuration Examples
    info!("\nâš™ï¸  7. Configuration Examples");
    info!("=============================");
    
    // Different configurations for different use cases
    let _qa_splitter = SentenceSplitter::from_defaults(300, 50)?; // Q&A systems
    let _summary_splitter = SentenceSplitter::from_defaults(800, 100)?; // Summarization
    let _search_splitter = SentenceSplitter::from_defaults(500, 75)?; // Semantic search
    
    info!("Q&A åˆ†å‰²å™¨: chunk_size=300, overlap=50");
    info!("æ‘˜è¦åˆ†å‰²å™¨: chunk_size=800, overlap=100");
    info!("æœç´¢åˆ†å‰²å™¨: chunk_size=500, overlap=75");

    // Markdown configurations
    let doc_config = MarkdownConfig::for_documentation();
    let blog_config = MarkdownConfig::for_blog_posts();
    let readme_config = MarkdownConfig::for_readme();
    
    info!("æ–‡æ¡£é…ç½®: max_depth={}, min_length={}", 
          doc_config.max_header_depth, doc_config.min_section_length);
    info!("åšå®¢é…ç½®: max_depth={}, separator='{}'", 
          blog_config.max_header_depth, blog_config.header_path_separator);
    info!("READMEé…ç½®: max_depth={}, min_length={}", 
          readme_config.max_header_depth, readme_config.min_section_length);

    info!("\nâœ… Parser Showcase å®Œæˆ!");
    info!("\nğŸ’¡ ä½¿ç”¨å»ºè®®:");
    info!("   â€¢ é€šç”¨æ–‡æ¡£å¤„ç†: ä½¿ç”¨ SentenceSplitter");
    info!("   â€¢ LLM åº”ç”¨: ä½¿ç”¨ TokenTextSplitter æ§åˆ¶ token æ•°é‡");
    info!("   â€¢ Markdown æ–‡æ¡£: ä½¿ç”¨ MarkdownNodeParser ä¿æŒç»“æ„");
    info!("   â€¢ é—®ç­”ç³»ç»Ÿ: ä½¿ç”¨ SentenceWindowNodeParser æä¾›ä¸Šä¸‹æ–‡");
    info!("   â€¢ ä»£ç åˆ†æ: ä½¿ç”¨ CodeSplitter ä¿æŒä»£ç ç»“æ„");

    Ok(())
}
