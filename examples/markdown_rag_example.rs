//! Markdownæ–‡ä»¶å¤¹RAGé—®ç­”ç¤ºä¾‹
//!
//! è¿™ä¸ªç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨Cheungfunæ¡†æ¶æ„å»ºä¸€ä¸ªå®Œæ•´çš„RAGç³»ç»Ÿï¼š
//! 1. æ‰¹é‡åŠ è½½æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰markdownæ–‡ä»¶
//! 2. ä½¿ç”¨çœŸå®LLM APIè¿›è¡ŒåµŒå…¥å’Œé—®ç­”
//! 3. æ”¯æŒå†…å­˜æˆ–SQLiteå­˜å‚¨
//! 4. æä¾›äº¤äº’å¼é—®ç­”åŠŸèƒ½
//!
//! ## ä½¿ç”¨æ–¹æ³•
//!
//! ```bash
//! # è®¾ç½®OpenAI APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œä¼šå›é€€åˆ°Ollamaï¼‰
//! export OPENAI_API_KEY="your-api-key-here"
//!
//! # è¿è¡Œç¤ºä¾‹
//! cargo run --example markdown_rag_example --features "fastembed,sqlite"
//!
//! # æˆ–ä½¿ç”¨æœ¬åœ°Ollama
//! ollama serve
//! ollama pull llama3.2
//! cargo run --example markdown_rag_example --features "fastembed"
//! ```
//!
//! ## åŠŸèƒ½ç‰¹æ€§
//!
//! - ğŸ—‚ï¸ æ‰¹é‡å¤„ç†markdownæ–‡ä»¶
//! - ğŸ¤– çœŸå®LLMé›†æˆï¼ˆOpenAI/Ollamaï¼‰
//! - ğŸ’¾ çµæ´»å­˜å‚¨é€‰æ‹©ï¼ˆå†…å­˜/SQLiteï¼‰
//! - ğŸ” è¯­ä¹‰æœç´¢å’Œé—®ç­”
//! - ğŸ“Š è¯¦ç»†çš„å¤„ç†ç»Ÿè®¡
//! - ğŸ¯ äº¤äº’å¼æŸ¥è¯¢ç•Œé¢

use cheungfun_core::{
    traits::{Embedder, Loader, NodeTransformer, Transformer, VectorStore},
    Result,
};
use cheungfun_indexing::{
    loaders::{DirectoryLoader, LoaderConfig},
    prelude::SplitterConfig,
    transformers::{MetadataExtractor, TextSplitter},
};
use cheungfun_integrations::{FastEmbedder, InMemoryVectorStore};
use cheungfun_query::{
    engine::{QueryEngine, QueryEngineBuilder},
    generator::SiumaiGenerator,
    retriever::VectorRetriever,
};
use siumai::prelude::*;
use std::{
    io::{self, Write},
    path::PathBuf,
    sync::Arc,
};
use tokio::fs;
use tracing::{info, warn, Level};

/// é…ç½®ç»“æ„ä½“
#[derive(Debug, Clone)]
pub struct RagConfig {
    /// markdownæ–‡ä»¶å¤¹è·¯å¾„
    pub docs_folder: PathBuf,
    /// æ˜¯å¦ä½¿ç”¨SQLiteå­˜å‚¨ï¼ˆå¦åˆ™ä½¿ç”¨å†…å­˜ï¼‰
    pub use_sqlite: bool,
    /// æ–‡æœ¬åˆ†å—å¤§å°
    pub chunk_size: usize,
    /// åˆ†å—é‡å å¤§å°
    pub chunk_overlap: usize,
    /// æ£€ç´¢æ—¶è¿”å›çš„top-kç»“æœæ•°
    pub top_k: usize,
    /// LLMæä¾›å•†ï¼ˆopenai/ollamaï¼‰
    pub llm_provider: String,
    /// LLMæ¨¡å‹åç§°
    pub llm_model: String,
}

impl Default for RagConfig {
    fn default() -> Self {
        Self {
            docs_folder: PathBuf::from("./docs"),
            use_sqlite: false,
            chunk_size: 500,
            chunk_overlap: 50,
            top_k: 5,
            llm_provider: "openai".to_string(),
            llm_model: "gpt-3.5-turbo".to_string(),
        }
    }
}

/// RAGç³»ç»Ÿç»„ä»¶
pub struct MarkdownRagSystem {
    config: RagConfig,
    embedder: Arc<dyn Embedder>,
    vector_store: Arc<dyn VectorStore>,
    query_engine: QueryEngine,
}

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt()
        .with_max_level(Level::INFO)
        .with_target(false)
        .init();

    println!("ğŸš€ Cheungfun Markdown RAG é—®ç­”ç³»ç»Ÿ");
    println!("=====================================");

    // è§£æé…ç½®
    let config = parse_config_from_args();

    // æ£€æŸ¥æ–‡æ¡£æ–‡ä»¶å¤¹
    if !config.docs_folder.exists() {
        create_sample_markdown_docs(&config.docs_folder).await?;
    }

    // åˆå§‹åŒ–RAGç³»ç»Ÿ
    let mut rag_system = MarkdownRagSystem::new(config).await?;

    // æ„å»ºç´¢å¼•
    rag_system.build_index().await?;

    // å¯åŠ¨äº¤äº’å¼é—®ç­”
    rag_system.start_interactive_chat().await?;

    Ok(())
}

impl MarkdownRagSystem {
    /// åˆ›å»ºæ–°çš„RAGç³»ç»Ÿ
    pub async fn new(config: RagConfig) -> Result<Self> {
        info!("ğŸ”§ åˆå§‹åŒ–RAGç³»ç»Ÿç»„ä»¶...");

        // 1. åˆå§‹åŒ–åµŒå…¥å™¨
        info!("  ğŸ“Š åˆå§‹åŒ–FastEmbedåµŒå…¥å™¨...");
        let embedder = Arc::new(FastEmbedder::new().await.map_err(|e| {
            cheungfun_core::CheungfunError::Configuration {
                message: format!("Failed to initialize FastEmbedder: {}", e),
            }
        })?);
        info!("    âœ… åµŒå…¥å™¨å°±ç»ª (ç»´åº¦: {})", embedder.dimension());

        // 2. åˆå§‹åŒ–å‘é‡å­˜å‚¨
        let vector_store: Arc<dyn VectorStore> = if config.use_sqlite {
            info!("  ğŸ—„ï¸ åˆå§‹åŒ–SQLiteå‘é‡å­˜å‚¨...");
            // TODO: å®ç°SQLiteå­˜å‚¨
            warn!("    âš ï¸ SQLiteå­˜å‚¨æš‚æœªå®ç°ï¼Œä½¿ç”¨å†…å­˜å­˜å‚¨");
            Arc::new(InMemoryVectorStore::new(
                embedder.dimension(),
                cheungfun_core::traits::DistanceMetric::Cosine,
            ))
        } else {
            info!("  ğŸ—„ï¸ åˆå§‹åŒ–å†…å­˜å‘é‡å­˜å‚¨...");
            Arc::new(InMemoryVectorStore::new(
                embedder.dimension(),
                cheungfun_core::traits::DistanceMetric::Cosine,
            ))
        };
        info!("    âœ… å‘é‡å­˜å‚¨å°±ç»ª");

        // 3. åˆ›å»ºLLMå®¢æˆ·ç«¯å’Œç”Ÿæˆå™¨
        info!("  ğŸ¤– åˆå§‹åŒ–LLMå®¢æˆ·ç«¯...");
        let generator = create_llm_generator(&config).await?;
        info!("    âœ… LLMç”Ÿæˆå™¨å°±ç»ª");

        // 4. åˆ›å»ºæŸ¥è¯¢å¼•æ“
        let retriever = Arc::new(VectorRetriever::new(vector_store.clone(), embedder.clone()));

        // åˆ›å»ºæŸ¥è¯¢å¼•æ“é…ç½®
        let engine_config = cheungfun_query::engine::QueryEngineConfig {
            default_top_k: config.top_k,
            default_generation_options: cheungfun_core::types::GenerationOptions::default(),
            validate_context: true,
            min_context_nodes: 1,
            max_context_nodes: 10,
            enable_query_preprocessing: true,
            enable_response_postprocessing: true,
        };

        let query_engine = QueryEngineBuilder::new()
            .retriever(retriever)
            .generator(Arc::new(generator))
            .config(engine_config)
            .build()?;

        Ok(Self {
            config,
            embedder,
            vector_store,
            query_engine,
        })
    }

    /// æ„å»ºæ–‡æ¡£ç´¢å¼•
    pub async fn build_index(&mut self) -> Result<()> {
        info!("ğŸ“š å¼€å§‹æ„å»ºæ–‡æ¡£ç´¢å¼•...");
        let start_time = std::time::Instant::now();

        // 1. é…ç½®æ–‡ä»¶åŠ è½½å™¨ï¼Œåªå¤„ç†markdownæ–‡ä»¶
        let loader_config = LoaderConfig::new()
            .with_include_extensions(vec!["md".to_string()])
            .with_max_depth(10)
            .with_continue_on_error(true);

        // 2. åŠ è½½æ‰€æœ‰markdownæ–‡ä»¶
        info!("  ğŸ“‚ æ‰«ææ–‡ä»¶å¤¹: {}", self.config.docs_folder.display());
        let loader = DirectoryLoader::with_config(&self.config.docs_folder, loader_config)?;
        let documents = loader.load().await?;

        if documents.is_empty() {
            warn!("  âš ï¸ æœªæ‰¾åˆ°ä»»ä½•markdownæ–‡ä»¶");
            return Ok(());
        }

        info!("  âœ… åŠ è½½äº† {} ä¸ªmarkdownæ–‡ä»¶", documents.len());

        // 3. é…ç½®æ–‡æœ¬åˆ†å‰²å™¨
        let splitter_config = SplitterConfig {
            chunk_size: self.config.chunk_size,
            chunk_overlap: self.config.chunk_overlap,
            separators: vec![
                "\n\n".to_string(),
                "\n".to_string(),
                ". ".to_string(),
                "ã€‚".to_string(),
            ],
            keep_separators: true,
            ..Default::default()
        };
        let text_splitter = TextSplitter::with_config(splitter_config);
        let metadata_extractor = MetadataExtractor::new();

        // 4. å¤„ç†æ¯ä¸ªæ–‡æ¡£
        let mut all_nodes = Vec::new();
        let mut total_chunks = 0;

        for (i, document) in documents.iter().enumerate() {
            info!(
                "  ğŸ“„ å¤„ç†æ–‡æ¡£ {}/{}: {}",
                i + 1,
                documents.len(),
                document
                    .get_metadata_string("file_path")
                    .unwrap_or_else(|| format!("Document {}", i + 1))
            );

            // åˆ†å‰²æ–‡æ¡£
            let nodes = text_splitter.transform(document.clone()).await?;
            info!("    âœ‚ï¸ åˆ†å‰²ä¸º {} ä¸ªå—", nodes.len());
            total_chunks += nodes.len();

            // æå–å…ƒæ•°æ®å¹¶ç”ŸæˆåµŒå…¥
            for mut node in nodes {
                // æå–å…ƒæ•°æ®
                node = metadata_extractor.transform_node(node).await?;

                // ç”ŸæˆåµŒå…¥
                let embedding = self.embedder.embed(&node.content).await?;
                node.embedding = Some(embedding);

                all_nodes.push(node);
            }
        }

        info!("  ğŸ§® ç”Ÿæˆäº† {} ä¸ªæ–‡æœ¬å—çš„åµŒå…¥", all_nodes.len());

        // 5. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        info!("  ğŸ’¾ å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“...");
        let stored_ids = self.vector_store.add(all_nodes).await?;

        let elapsed = start_time.elapsed();
        info!("âœ… ç´¢å¼•æ„å»ºå®Œæˆ!");
        info!("  ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:");
        info!("    - å¤„ç†æ–‡æ¡£: {} ä¸ª", documents.len());
        info!("    - ç”Ÿæˆå—: {} ä¸ª", total_chunks);
        info!("    - å­˜å‚¨èŠ‚ç‚¹: {} ä¸ª", stored_ids.len());
        info!("    - å¤„ç†æ—¶é—´: {:?}", elapsed);
        info!("    - å¹³å‡æ¯æ–‡æ¡£: {:?}", elapsed / documents.len() as u32);

        Ok(())
    }

    /// å¯åŠ¨äº¤äº’å¼é—®ç­”
    pub async fn start_interactive_chat(&self) -> Result<()> {
        info!("ğŸ¯ å¯åŠ¨äº¤äº’å¼é—®ç­”æ¨¡å¼");
        println!("\nğŸ’¬ RAGé—®ç­”ç³»ç»Ÿå·²å°±ç»ªï¼");
        println!("æç¤ºï¼š");
        println!("  - è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯");
        println!("  - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º");
        println!("  - è¾“å…¥ 'stats' æŸ¥çœ‹ç³»ç»Ÿç»Ÿè®¡");
        println!("  - è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©");
        println!("{}", "=".repeat(50));

        loop {
            // æ˜¾ç¤ºæç¤ºç¬¦
            print!("\nğŸ¤” æ‚¨çš„é—®é¢˜: ");
            io::stdout().flush().unwrap();

            // è¯»å–ç”¨æˆ·è¾“å…¥
            let mut input = String::new();
            match io::stdin().read_line(&mut input) {
                Ok(_) => {
                    let query = input.trim();

                    // å¤„ç†ç‰¹æ®Šå‘½ä»¤
                    match query.to_lowercase().as_str() {
                        "quit" | "exit" => {
                            println!("ğŸ‘‹ å†è§ï¼");
                            break;
                        }
                        "stats" => {
                            self.show_system_stats().await?;
                            continue;
                        }
                        "help" => {
                            self.show_help();
                            continue;
                        }
                        "" => continue,
                        _ => {}
                    }

                    // å¤„ç†æŸ¥è¯¢
                    match self.process_query(query).await {
                        Ok(_) => {}
                        Err(e) => {
                            println!("âŒ æŸ¥è¯¢å¤±è´¥: {}", e);
                        }
                    }
                }
                Err(e) => {
                    println!("âŒ è¯»å–è¾“å…¥å¤±è´¥: {}", e);
                    break;
                }
            }
        }

        Ok(())
    }

    /// å¤„ç†å•ä¸ªæŸ¥è¯¢
    async fn process_query(&self, query: &str) -> Result<()> {
        println!("ğŸ” æ­£åœ¨æœç´¢ç›¸å…³å†…å®¹...");
        let start_time = std::time::Instant::now();

        // æ‰§è¡ŒæŸ¥è¯¢
        let response = self.query_engine.query(query).await?;
        let elapsed = start_time.elapsed();

        // æ˜¾ç¤ºç»“æœ
        println!("\nğŸ¤– AIå›ç­”:");
        println!("{}", "â”€".repeat(50));
        println!("{}", response.response.content);
        println!("{}", "â”€".repeat(50));

        // æ˜¾ç¤ºæ£€ç´¢ä¿¡æ¯
        println!(
            "\nğŸ“š å‚è€ƒæ¥æº ({} ä¸ªç›¸å…³ç‰‡æ®µ):",
            response.retrieved_nodes.len()
        );
        for (i, scored_node) in response.retrieved_nodes.iter().take(3).enumerate() {
            let source = scored_node
                .node
                .get_metadata_string("file_path")
                .unwrap_or_else(|| "æœªçŸ¥æ¥æº".to_string());
            let preview = scored_node
                .node
                .content
                .chars()
                .take(100)
                .collect::<String>();

            println!("  {}. [ç›¸ä¼¼åº¦: {:.3}] {}", i + 1, scored_node.score, source);
            println!("     é¢„è§ˆ: {}...", preview);
        }

        // æ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
        println!("\nâš¡ æ€§èƒ½ä¿¡æ¯:");
        println!("  - æŸ¥è¯¢æ—¶é—´: {:?}", elapsed);
        if let Some(usage) = &response.response.usage {
            println!(
                "  - Tokenä½¿ç”¨: {} prompt + {} completion = {} total",
                usage.prompt_tokens, usage.completion_tokens, usage.total_tokens
            );
        }

        Ok(())
    }

    /// æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
    async fn show_system_stats(&self) -> Result<()> {
        println!("\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯");
        println!("{}", "=".repeat(30));

        // å‘é‡å­˜å‚¨ç»Ÿè®¡
        let node_count = self.vector_store.count().await?;
        let store_metadata = self.vector_store.metadata().await?;

        println!("ğŸ—„ï¸ å‘é‡å­˜å‚¨:");
        println!("  - å­˜å‚¨èŠ‚ç‚¹æ•°: {}", node_count);
        println!(
            "  - å­˜å‚¨ç±»å‹: {}",
            store_metadata.get("type").unwrap_or(&"unknown".into())
        );
        println!(
            "  - å‘é‡ç»´åº¦: {}",
            store_metadata.get("dimension").unwrap_or(&"unknown".into())
        );

        // åµŒå…¥å™¨ç»Ÿè®¡
        let embedder_metadata = self.embedder.metadata();
        println!("ğŸ“Š åµŒå…¥å™¨:");
        println!("  - æ¨¡å‹: {}", self.embedder.model_name());
        println!("  - ç»´åº¦: {}", self.embedder.dimension());
        println!(
            "  - å·²åµŒå…¥æ–‡æœ¬æ•°: {}",
            embedder_metadata.get("texts_embedded").unwrap_or(&0.into())
        );

        // é…ç½®ä¿¡æ¯
        println!("âš™ï¸ é…ç½®:");
        println!("  - æ–‡æ¡£æ–‡ä»¶å¤¹: {}", self.config.docs_folder.display());
        println!("  - åˆ†å—å¤§å°: {}", self.config.chunk_size);
        println!("  - åˆ†å—é‡å : {}", self.config.chunk_overlap);
        println!("  - Top-K: {}", self.config.top_k);
        println!("  - LLMæä¾›å•†: {}", self.config.llm_provider);
        println!("  - LLMæ¨¡å‹: {}", self.config.llm_model);

        // å¥åº·æ£€æŸ¥
        println!("ğŸ¥ å¥åº·æ£€æŸ¥:");
        match self.vector_store.health_check().await {
            Ok(()) => println!("  - å‘é‡å­˜å‚¨: âœ… æ­£å¸¸"),
            Err(e) => println!("  - å‘é‡å­˜å‚¨: âŒ é”™è¯¯: {}", e),
        }

        match self.embedder.health_check().await {
            Ok(()) => println!("  - åµŒå…¥å™¨: âœ… æ­£å¸¸"),
            Err(e) => println!("  - åµŒå…¥å™¨: âŒ é”™è¯¯: {}", e),
        }

        Ok(())
    }

    /// æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    fn show_help(&self) {
        println!("\nğŸ“– å¸®åŠ©ä¿¡æ¯");
        println!("{}", "=".repeat(30));
        println!("å¯ç”¨å‘½ä»¤:");
        println!("  help  - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯");
        println!("  stats - æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯");
        println!("  quit  - é€€å‡ºç¨‹åº");
        println!("  exit  - é€€å‡ºç¨‹åº");
        println!("\nä½¿ç”¨æŠ€å·§:");
        println!("  - å°½é‡ä½¿ç”¨å…·ä½“ã€æ¸…æ™°çš„é—®é¢˜");
        println!("  - å¯ä»¥è¯¢é—®æ–‡æ¡£ä¸­çš„å…·ä½“å†…å®¹");
        println!("  - æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡é—®ç­”");
        println!("  - ç³»ç»Ÿä¼šè‡ªåŠ¨æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ");
    }
}

/// è§£æå‘½ä»¤è¡Œå‚æ•°é…ç½®
fn parse_config_from_args() -> RagConfig {
    let mut config = RagConfig::default();

    // ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    if let Ok(docs_path) = std::env::var("DOCS_FOLDER") {
        config.docs_folder = PathBuf::from(docs_path);
    }

    if let Ok(chunk_size) = std::env::var("CHUNK_SIZE") {
        if let Ok(size) = chunk_size.parse::<usize>() {
            config.chunk_size = size;
        }
    }

    if let Ok(top_k) = std::env::var("TOP_K") {
        if let Ok(k) = top_k.parse::<usize>() {
            config.top_k = k;
        }
    }

    // æ£€æµ‹LLMæä¾›å•†
    if std::env::var("OPENAI_API_KEY").is_ok() {
        config.llm_provider = "openai".to_string();
        config.llm_model = "gpt-3.5-turbo".to_string();
    } else {
        config.llm_provider = "ollama".to_string();
        config.llm_model = "llama3.2".to_string();
    }

    config
}

/// åˆ›å»ºLLMç”Ÿæˆå™¨
async fn create_llm_generator(config: &RagConfig) -> Result<SiumaiGenerator> {
    match config.llm_provider.as_str() {
        "openai" => {
            let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
                cheungfun_core::CheungfunError::Configuration {
                    message: "OPENAI_API_KEY environment variable not set".to_string(),
                }
            })?;

            let client = Siumai::builder()
                .openai()
                .api_key(&api_key)
                .model(&config.llm_model)
                .temperature(0.7)
                .max_tokens(1000)
                .build()
                .await
                .map_err(|e| cheungfun_core::CheungfunError::Configuration {
                    message: format!("Failed to create OpenAI client: {}", e),
                })?;

            Ok(SiumaiGenerator::new(client))
        }
        "ollama" => {
            let client = Siumai::builder()
                .ollama()
                .base_url("http://localhost:11434")
                .model(&config.llm_model)
                .temperature(0.7)
                .max_tokens(1000)
                .build()
                .await
                .map_err(|e| cheungfun_core::CheungfunError::Configuration {
                    message: format!("Failed to create Ollama client: {}", e),
                })?;

            Ok(SiumaiGenerator::new(client))
        }
        _ => Err(cheungfun_core::CheungfunError::Configuration {
            message: format!("Unsupported LLM provider: {}", config.llm_provider),
        }),
    }
}

/// åˆ›å»ºç¤ºä¾‹markdownæ–‡æ¡£
async fn create_sample_markdown_docs(docs_folder: &PathBuf) -> Result<()> {
    info!("ğŸ“ åˆ›å»ºç¤ºä¾‹markdownæ–‡æ¡£...");

    fs::create_dir_all(docs_folder)
        .await
        .map_err(|e| cheungfun_core::CheungfunError::Io(e))?;

    let sample_docs = vec![
        (
            "rust_basics.md",
            r#"# Rustç¼–ç¨‹è¯­è¨€åŸºç¡€

## ä»€ä¹ˆæ˜¯Rustï¼Ÿ

Rustæ˜¯ä¸€ç§ç³»ç»Ÿç¼–ç¨‹è¯­è¨€ï¼Œä¸“æ³¨äºå®‰å…¨æ€§ã€é€Ÿåº¦å’Œå¹¶å‘æ€§ã€‚å®ƒç”±Mozillaå¼€å‘ï¼Œæ—¨åœ¨è§£å†³Cå’ŒC++ä¸­å¸¸è§çš„å†…å­˜å®‰å…¨é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒé«˜æ€§èƒ½ã€‚

## Rustçš„æ ¸å¿ƒç‰¹æ€§

### 1. å†…å­˜å®‰å…¨
Rusté€šè¿‡æ‰€æœ‰æƒç³»ç»Ÿï¼ˆOwnership Systemï¼‰åœ¨ç¼–è¯‘æ—¶é˜²æ­¢å†…å­˜æ³„æ¼ã€æ‚¬ç©ºæŒ‡é’ˆå’Œæ•°æ®ç«äº‰ç­‰é—®é¢˜ã€‚

### 2. é›¶æˆæœ¬æŠ½è±¡
Rustæä¾›é«˜çº§æŠ½è±¡ï¼Œä½†ä¸ä¼šäº§ç”Ÿè¿è¡Œæ—¶å¼€é”€ã€‚ç¼–è¯‘å™¨ä¼šä¼˜åŒ–ä»£ç ï¼Œä½¿æŠ½è±¡çš„æˆæœ¬ä¸ºé›¶ã€‚

### 3. å¹¶å‘å®‰å…¨
Rustçš„ç±»å‹ç³»ç»Ÿé˜²æ­¢æ•°æ®ç«äº‰ï¼Œä½¿å¹¶å‘ç¼–ç¨‹æ›´åŠ å®‰å…¨ã€‚

## Rustçš„åº”ç”¨é¢†åŸŸ

- ç³»ç»Ÿç¼–ç¨‹ï¼šæ“ä½œç³»ç»Ÿå†…æ ¸ã€è®¾å¤‡é©±åŠ¨ç¨‹åº
- Webå¼€å‘ï¼šWebæœåŠ¡å™¨ã€APIæœåŠ¡
- åŒºå—é“¾ï¼šä»¥å¤ªåŠå®¢æˆ·ç«¯ã€åŠ å¯†è´§å¸é’±åŒ…
- æ¸¸æˆå¼€å‘ï¼šæ¸¸æˆå¼•æ“ã€é«˜æ€§èƒ½æ¸¸æˆé€»è¾‘
- æœºå™¨å­¦ä¹ ï¼šé«˜æ€§èƒ½è®¡ç®—åº“ã€æ•°æ®å¤„ç†å·¥å…·
"#,
        ),
        (
            "rag_introduction.md",
            r#"# RAGç³»ç»Ÿä»‹ç»

## ä»€ä¹ˆæ˜¯RAGï¼Ÿ

RAGï¼ˆRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ä¸€ç§ç»“åˆä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬ç”Ÿæˆçš„AIæŠ€æœ¯ã€‚å®ƒé€šè¿‡ä»å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„å›ç­”èƒ½åŠ›ã€‚

## RAGçš„å·¥ä½œåŸç†

### 1. çŸ¥è¯†åº“æ„å»ºé˜¶æ®µ
- æ–‡æ¡£å¤„ç†ï¼šåŠ è½½ã€æå–ã€åˆ†å‰²æ–‡æ¡£
- å‘é‡åŒ–å­˜å‚¨ï¼šæ–‡æœ¬åµŒå…¥ã€å‘é‡å­˜å‚¨ã€ç´¢å¼•æ„å»º

### 2. æŸ¥è¯¢å¤„ç†é˜¶æ®µ
- æ£€ç´¢è¿‡ç¨‹ï¼šæŸ¥è¯¢åµŒå…¥ã€ç›¸ä¼¼æ€§æœç´¢ã€ç»“æœæ’åº
- ç”Ÿæˆè¿‡ç¨‹ï¼šä¸Šä¸‹æ–‡ç»„è£…ã€æç¤ºæ„å»ºã€æ–‡æœ¬ç”Ÿæˆ

## RAGçš„ä¼˜åŠ¿

- çŸ¥è¯†æ›´æ–°ï¼šå®æ—¶æ€§ã€å‡†ç¡®æ€§ã€å¯è¿½æº¯æ€§
- æˆæœ¬æ•ˆç›Šï¼šæ— éœ€é‡è®­ç»ƒã€èµ„æºèŠ‚çº¦ã€çµæ´»æ€§
- å¯æ§æ€§ï¼šå†…å®¹æ§åˆ¶ã€è´¨é‡ä¿è¯ã€éšç§ä¿æŠ¤

## RAGç³»ç»Ÿçš„ç»„ä»¶

1. æ–‡æ¡£åŠ è½½å™¨ï¼šä»å„ç§æ•°æ®æºåŠ è½½æ–‡æ¡£
2. æ–‡æœ¬å¤„ç†å™¨ï¼šå¤„ç†å’Œå‡†å¤‡æ–‡æœ¬æ•°æ®
3. åµŒå…¥æ¨¡å‹ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
4. å‘é‡æ•°æ®åº“ï¼šå­˜å‚¨å’Œæ£€ç´¢å‘é‡
5. æ£€ç´¢å™¨ï¼šæ‰§è¡Œç›¸ä¼¼æ€§æœç´¢
6. ç”Ÿæˆå™¨ï¼šç”Ÿæˆæœ€ç»ˆå›ç­”
"#,
        ),
        (
            "ai_development.md",
            r#"# AIå¼€å‘å®è·µæŒ‡å—

## AIå¼€å‘æ¦‚è¿°

äººå·¥æ™ºèƒ½å¼€å‘æ˜¯ä¸€ä¸ªæ¶‰åŠå¤šä¸ªå­¦ç§‘çš„å¤æ‚è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰å¤šä¸ªé¢†åŸŸã€‚

## AIå¼€å‘ç”Ÿå‘½å‘¨æœŸ

### 1. é—®é¢˜å®šä¹‰é˜¶æ®µ
- ä¸šåŠ¡ç†è§£ï¼šéœ€æ±‚åˆ†æã€å¯è¡Œæ€§è¯„ä¼°ã€æˆåŠŸæŒ‡æ ‡ã€é£é™©è¯„ä¼°
- é—®é¢˜å»ºæ¨¡ï¼šé—®é¢˜ç±»å‹ã€è¾“å…¥è¾“å‡ºã€çº¦æŸæ¡ä»¶ã€è¯„ä¼°æ ‡å‡†

### 2. æ•°æ®å‡†å¤‡é˜¶æ®µ
- æ•°æ®æ”¶é›†ï¼šæ•°æ®æºè¯†åˆ«ã€è´¨é‡è¯„ä¼°ã€åˆè§„æ€§ã€æ•°æ®å­˜å‚¨
- æ•°æ®é¢„å¤„ç†ï¼šæ•°æ®æ¸…ç†ã€ç‰¹å¾å·¥ç¨‹ã€æ•°æ®å˜æ¢

### 3. æ¨¡å‹å¼€å‘é˜¶æ®µ
- æ¨¡å‹é€‰æ‹©ï¼šä¼ ç»Ÿæœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€é›†æˆæ–¹æ³•ã€é¢„è®­ç»ƒæ¨¡å‹
- æ¨¡å‹è®­ç»ƒï¼šæ•°æ®åˆ†å‰²ã€æ¨¡å‹è®­ç»ƒã€äº¤å‰éªŒè¯ã€æ¨¡å‹è¯„ä¼°

### 4. æ¨¡å‹è¯„ä¼°é˜¶æ®µ
- è¯„ä¼°æŒ‡æ ‡ï¼šåˆ†ç±»ã€å›å½’ã€ç”Ÿæˆã€æ£€ç´¢ä»»åŠ¡çš„ä¸åŒæŒ‡æ ‡
- æ¨¡å‹è§£é‡Šæ€§ï¼šç‰¹å¾é‡è¦æ€§ã€SHAPå€¼ã€LIMEã€æ³¨æ„åŠ›æœºåˆ¶

### 5. éƒ¨ç½²å’Œç›‘æ§é˜¶æ®µ
- æ¨¡å‹éƒ¨ç½²ï¼šAPIæœåŠ¡ã€å®¹å™¨åŒ–ã€äº‘éƒ¨ç½²
- æ¨¡å‹ç›‘æ§ï¼šæ€§èƒ½ç›‘æ§ã€æ•°æ®æ¼‚ç§»æ£€æµ‹ã€A/Bæµ‹è¯•

## AIå¼€å‘æœ€ä½³å®è·µ

1. æ•°æ®ç®¡ç†ï¼šç‰ˆæœ¬æ§åˆ¶ã€æ•°æ®è¡€ç¼˜ã€è´¨é‡ç›‘æ§ã€éšç§ä¿æŠ¤
2. å®éªŒç®¡ç†ï¼šå®éªŒè·Ÿè¸ªã€è¶…å‚æ•°ä¼˜åŒ–ã€æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ã€å¯é‡ç°æ€§
3. ä»£ç è´¨é‡ï¼šæ¨¡å—åŒ–è®¾è®¡ã€å•å…ƒæµ‹è¯•ã€ä»£ç å®¡æŸ¥ã€æ–‡æ¡£ç¼–å†™
4. å›¢é˜Ÿåä½œï¼šè§’è‰²åˆ†å·¥ã€æ²Ÿé€šæœºåˆ¶ã€çŸ¥è¯†å…±äº«ã€æŠ€èƒ½åŸ¹è®­
"#,
        ),
    ];

    for (filename, content) in sample_docs {
        let file_path = docs_folder.join(filename);
        fs::write(&file_path, content)
            .await
            .map_err(|e| cheungfun_core::CheungfunError::Io(e))?;
    }

    info!("  âœ… åˆ›å»ºäº† {} ä¸ªç¤ºä¾‹æ–‡æ¡£", 3);
    Ok(())
}
