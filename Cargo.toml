[workspace]
resolver = "2"
members = [
    "cheungfun",
    "cheungfun-core",
    "cheungfun-indexing",
    "cheungfun-query",
    "cheungfun-agents",
    "cheungfun-integrations",
    "cheungfun-multimodal",
    "examples",
    "tools",
]
# "cheungfun-evaluation",
# "cheungfun-workflow",
# "cheungfun-training",
default-members = ["cheungfun", "cheungfun-*"]

[workspace.package]
version = "0.1.0"
authors = ["Mingzhen Zhuang"]
edition = "2021"
license = "MIT OR Apache-2.0"
repository = "https://github.com/YumchaLabs/cheungfun"
homepage = "https://github.com/YumchaLabs/cheungfun"
documentation = "https://docs.rs/cheungfun"
keywords = ["llm", "rag", "ai", "data", "rust"]
description = "Fast, streaming indexing, query, and agentic LLM applications in Rust"
categories = ["asynchronous", "science"]

[workspace.metadata]
# Project Metadata
name = "cheungfun"
keywords = ["ai", "llm", "rag"]

[workspace.dependencies]
# Core dependencies
siumai = "0.9.0"
tokio = { version = "1.47", features = ["rt-multi-thread", "time", "macros"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
thiserror = "2.0"
async-trait = "0.1"
uuid = { version = "1.18", features = ["v4", "serde"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Async and streaming
futures = "0.3"
futures-util = "0.3"
tokio-stream = "0.1"
pin-project = "1.1"

# Data processing
text-splitter = "0.27"
tiktoken-rs = "0.7"
regex = "1.11"
itertools = "0.14"
rand = "0.8"

# Serialization and config
toml = "0.9"
config = "0.15"
bincode = { version = "2", features = ["serde"] }

# Caching
cached = { version = "0.56", features = ["disk_store", "async"] }

# Performance optimization
rayon = "1.11"
num_cpus = "1.16"

# Document processing
pdf-extract = "0.9"
docx-rs = "0.4"
csv = "1.3"
scraper = "0.24"

# HTTP and networking
reqwest = { version = "0.12", features = ["json", "stream"] }
url = "2.5"
axum = "0.8"
tower = "0.5"

# Database and storage
sqlx = { version = "0.8", features = ["postgres", "mysql", "sqlite", "runtime-tokio-rustls"] }
redis = { version = "0.32", features = ["tokio-comp"] }
sled = "0.34"
redb = "2.6"

# Candle ML Framework (Core)
candle-core = { version = "0.9", features = [] }
candle-nn = "0.9"
candle-transformers = "0.9"

# HuggingFace Integration
hf-hub = { version = "0.4", features = ["tokio"] }
tokenizers = "0.21"

# Alternative ML (optional) - disabled for now due to compatibility issues
# ort = "2.0"
# faiss = "0.12"

# Search and indexing
tantivy = "0.25"

# Vector stores
qdrant-client = { version = "1.15", features = ["serde"] }

# MCP (Model Context Protocol)
rmcp = "0.6"
schemars = "1"

# Multimodal processing
image = "0.25"
imageproc = "0.25"
rodio = "0.21"
hound = "3.5"
symphonia = "0.5"
ffmpeg-next = "7.0"
infer = "0.19"
base64 = "0.22"
sha2 = "0.10"
path-absolutize = "3.1"

# Workflow and training
petgraph = "0.8"

# Cloud storage
aws-sdk-s3 = "1.0"
google-cloud-storage = "0.24"
azure_storage = "0.21"
azure_storage_blobs = "0.21"

# Streaming and messaging
rdkafka = "0.37"
tungstenite = "0.24"

# Utilities
derive_builder = "0.20"
strum = { version = "0.27", features = ["derive"] }
chrono = { version = "0.4", features = ["serde"] }
lazy_static = "1.5"
once_cell = "1.20"

# Testing
mockall = "0.13"
test-case = "3.3"
pretty_assertions = "1.4"
temp-dir = "0.1"
tempfile = "3.21"
criterion = "0.7"

[workspace.lints.rust]
unsafe_code = "forbid"
missing_docs = "warn"

[workspace.lints.clippy]
cargo = { level = "warn", priority = -1 }
pedantic = { level = "warn", priority = -1 }
# Allow some pedantic lints that are too strict
module_name_repetitions = "allow"
must_use_candidate = "allow"
missing_errors_doc = "allow"
missing_panics_doc = "allow"

[profile.dev]
opt-level = 0
debug = true

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"

[profile.bench]
opt-level = 3
debug = false
lto = true

# Development profile for faster compilation
[profile.dev.package]
text-splitter.opt-level = 3
tiktoken-rs.opt-level = 3
candle-core.opt-level = 3
